#!/bin/bash
# Autogenerated by ClearML SLURM integration.

#
# Slurm job name.
#
#SBATCH --job-name=frcnn
#######################

#
# Slurm out log file.
#
#SBATCH --output=/net/people/plgszymswiat/dev/nih-classification/slurm_logs/out.log
#######################

#
# Slurm err log file.
#
#SBATCH --error=/net/people/plgszymswiat/dev/nih-classification/slurm_logs/err.log
#######################

#
# Job walltime.
#
#SBATCH --time=00-08:00:00
#######################

#
# GPUs per node.
#
#SBATCH --gres=gpu:1
#######################

#
# CPUs per node.
#
#SBATCH --cpus-per-task=8
#######################

#
# Requested nodes.
#
#SBATCH --mem=24576
#######################

#
# Signal that will be send before killing a job.
#
#SBATCH --signal=USR1@60
#######################

#
#
# Cluster specific options.
#
#

#
# 
#
#SBATCH --partition=plgrid-gpu-v100
#######################

#
# 
#
#SBATCH --constraint=localfs
#######################



srun python ./train_scripts/train_art_detection.py hparams=art_detection run_config=local