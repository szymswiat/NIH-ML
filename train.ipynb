{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import clearml\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import OmegaConf\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from callbacks.lr_callbacks import LrDecay, LrWarmup, LrExponential\n",
    "from data.nih_data_module import NIHDataModule\n",
    "from loggers.clearml_logger import ClearMLLogger\n",
    "from models.efficient_net_v2_module import EfficientNetV2Module\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "pl.seed_everything(42)\n",
    "\n",
    "cfg = OmegaConf.load('config/example/train.yaml')\n",
    "\n",
    "task = clearml.Task.init(project_name='Nih-classification',\n",
    "                         task_name=cfg.cluster.job_name,\n",
    "                         auto_connect_frameworks=False,\n",
    "                         output_uri=True)\n",
    "\n",
    "#\n",
    "# Extract and setup configuration from config file\n",
    "#\n",
    "log_ver = cfg.training.version\n",
    "rfc = cfg.training.restore_from_ckpt\n",
    "exp_root_dir = Path(cfg.training.log_dir) / cfg.cluster.job_name\n",
    "\n",
    "version = f'version_{log_ver}' if isinstance(log_ver, int) else log_ver\n",
    "\n",
    "exp_str = 'no_exp'\n",
    "\n",
    "log_dir = exp_root_dir / exp_str / version\n",
    "checkpoint_dir = log_dir / 'checkpoints'\n",
    "checkpoint_file = exp_root_dir / rfc if rfc else None\n",
    "\n",
    "es_cfg = cfg.training.early_stopping\n",
    "\n",
    "lr_decay_cfg = cfg.hparams.lr_decay\n",
    "lr_exponential_cfg = cfg.hparams.lr_exponential\n",
    "lr_warmup_cfg = cfg.hparams.lr_warmup\n",
    "\n",
    "#\n",
    "# Define callbacks\n",
    "#\n",
    "callbacks = []\n",
    "\n",
    "ckpt_params = dict(\n",
    "    dirpath=checkpoint_dir,\n",
    "    verbose=True,\n",
    "    save_top_k=3,\n",
    "    auto_insert_metric_name=False\n",
    ")\n",
    "max_auc_ckpt_cb = ModelCheckpoint(\n",
    "    filename='epoch={epoch}_val_auroc={auroc_avg/val:.3f}_top',\n",
    "    monitor='auroc_avg/val',\n",
    "    mode='max',\n",
    "    **ckpt_params\n",
    ")\n",
    "callbacks.append(max_auc_ckpt_cb)\n",
    "\n",
    "es_cb = EarlyStopping(\n",
    "    monitor=\"auc_roc_avg/val\",\n",
    "    min_delta=es_cfg.min_delta,\n",
    "    patience=es_cfg.patience,\n",
    "    verbose=True,\n",
    "    mode=\"max\"\n",
    ")\n",
    "if es_cfg.enabled:\n",
    "    callbacks.append(es_cb)\n",
    "\n",
    "# Note: LrDecay callback should be executed before LrWarmup\n",
    "lr_decay_cb = LrDecay(\n",
    "    rate=lr_decay_cfg.rate,\n",
    "    interval=lr_decay_cfg.interval,\n",
    "    initial_lr=cfg.hparams.lr_initial\n",
    ")\n",
    "if lr_decay_cfg.enabled:\n",
    "    callbacks.append(lr_decay_cb)\n",
    "\n",
    "# Note: LrExponential callback should be executed before LrWarmup\n",
    "lr_exponential_cb = LrExponential(\n",
    "    gamma=lr_exponential_cfg.gamma,\n",
    "    warmup_steps=lr_warmup_cfg.warmup_steps if lr_warmup_cfg.enabled else None,\n",
    "    phases=cfg.hparams.phases,\n",
    "    initial_lr=cfg.hparams.lr_initial\n",
    ")\n",
    "if lr_exponential_cfg.enabled:\n",
    "    callbacks.append(lr_exponential_cb)\n",
    "\n",
    "lr_warmup_cb = LrWarmup(\n",
    "    warmup_steps=lr_warmup_cfg.warmup_steps,\n",
    "    phases=cfg.hparams.phases,\n",
    "    initial_lr=cfg.hparams.lr_initial\n",
    ")\n",
    "if lr_warmup_cfg.enabled:\n",
    "    callbacks.append(lr_warmup_cb)\n",
    "\n",
    "#\n",
    "# Instantiate modules\n",
    "#\n",
    "dm = NIHDataModule(\n",
    "    dataset_path=cfg.data.dataset_path,\n",
    "    df_prefix=cfg.data.df_prefix,\n",
    "    phases=cfg.hparams.phases,\n",
    "    num_workers=cfg.cluster.cpus_per_node,\n",
    "    merge_train_val=cfg.data.merge_train_val\n",
    ")\n",
    "\n",
    "if cfg.hparams.architecture == 'eff_net_v2':\n",
    "    model = EfficientNetV2Module(num_classes=NIHDataModule.NUM_CLASSES,\n",
    "                                 class_freq=dm.get_train_class_freq(),\n",
    "                                 hparams=cfg.hparams)\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=cfg.hparams.epochs,\n",
    "    logger=ClearMLLogger(task),\n",
    "    deterministic=True,\n",
    "    num_sanity_val_steps=0,\n",
    "    callbacks=callbacks,\n",
    "    default_root_dir=checkpoint_dir,\n",
    "    resume_from_checkpoint=checkpoint_file,\n",
    "    reload_dataloaders_every_n_epochs=1,\n",
    "    limit_train_batches=100,\n",
    "    log_every_n_steps=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "task.flush()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}