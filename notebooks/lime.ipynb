{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.nih_efficient_net_v2_module import NIHEfficientNetV2Module\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import transforms as tfm\n",
    "from data.nih_dataset import NIHDataset\n",
    "\n",
    "\n",
    "model_path = Path('../lightning_logs/epoch=9_val_auroc=0.861_top.pt')\n",
    "\n",
    "dataset_path = Path('/home/szymswiat/datasets/nih_dataset')\n",
    "img_size = 384\n",
    "\n",
    "model = NIHEfficientNetV2Module.load_from_file(model_path)\n",
    "\n",
    "classes = OmegaConf.to_object(model.hparams.dynamic.classes)\n",
    "\n",
    "metadata = NIHDataset.parse_dataset_meta(\n",
    "    dataset_path=dataset_path,\n",
    "    split_type=NIHDataset.SPLIT_OFFICIAL_VAL_FROM_TEST,\n",
    "    classes=classes\n",
    ")\n",
    "transforms = A.Compose([\n",
    "    A.Resize(img_size, img_size),\n",
    "    tfm.NormalizeAlb(NIHDataset.MIN_MAX_VALUE,\n",
    "                     mean=[NIHDataset.MEAN] * 3,\n",
    "                     std=[NIHDataset.STD] * 3)\n",
    "])\n",
    "\n",
    "test_set = NIHDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    input_df=metadata['test_df'],\n",
    "    filter_by_positive_class=['Emphysema'],\n",
    "    # mode=NIHDataset.BBOX_ONLY_MODE\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "i = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "assert i < len(test_set)\n",
    "img_raw, y_true = test_set[i]\n",
    "img = transforms(image=img_raw)['image']\n",
    "y_pred = model(torch.unsqueeze(torch.tensor(img).permute(2, 0, 1), dim=0).float())\n",
    "y_pred_sum = y_pred.sum()\n",
    "i += 1\n",
    "\n",
    "emphysema_out = y_pred[0][3] >= 0.2575\n",
    "# 0.2575"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from imageio.plugins.pillow import ndarray_to_pil\n",
    "import cv2\n",
    "\n",
    "\n",
    "def predict(batch: np.ndarray):\n",
    "    batch = torch.tensor(batch, dtype=torch.float32).permute((0, 3, 1, 2))\n",
    "\n",
    "    outputs = model(batch)\n",
    "    return outputs.detach().numpy()\n",
    "\n",
    "\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "explanation = explainer.explain_instance(\n",
    "    img,\n",
    "    predict,  # classification function\n",
    "    labels=metadata['classes'],\n",
    "    hide_color=0,\n",
    "    batch_size=4,\n",
    "    num_samples=1000,\n",
    "    top_labels=6\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, mask = explanation.get_image_and_mask(classes.index('Cardiomegaly'),\n",
    "                                         positive_only=True, negative_only=False,\n",
    "                                         num_features=1, hide_rest=False)\n",
    "img_boundry2 = mark_boundaries(img_raw, cv2.resize(mask, img_raw.shape[:2], interpolation=cv2.INTER_NEAREST))\n",
    "ndarray_to_pil(img_boundry2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}