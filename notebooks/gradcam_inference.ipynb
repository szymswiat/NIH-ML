{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from inference.models.efficient_net_v2_module import EfficientNetV2Module\n",
    "from inference.models.resnet_module import ResNetModule\n",
    "\n",
    "# 00006160_001.png\n",
    "# 00014753_000.png\n",
    "# 00013613_007.png good example of shitty image\n",
    "# 00028730_000.png no finding\n",
    "\n",
    "model_path = Path('../lightning_logs/resnet34_epoch=17_val_auroc=0.843_top_updated.pt')\n",
    "dataset_path = Path('/home/szymswiat/datasets/nih_dataset')\n",
    "img_size = 384\n",
    "\n",
    "state = torch.load(model_path.as_posix())\n",
    "hparams = OmegaConf.create(state['hparams'])\n",
    "thresholds = torch.tensor(state['thresholds'])\n",
    "classes = OmegaConf.to_object(hparams.dynamic.classes)\n",
    "\n",
    "if hparams.architecture == 'eff_net_v2':\n",
    "    model_class = EfficientNetV2Module\n",
    "elif hparams.architecture == 'resnet':\n",
    "    model_class = ResNetModule\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "model = model_class.create_from_state(state)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensorV2\n",
    "from data.nih_dataset import NIHDataset\n",
    "import albumentations as A\n",
    "import transforms as tfm\n",
    "\n",
    "metadata = NIHDataset.parse_dataset_meta(\n",
    "    dataset_path=dataset_path,\n",
    "    split_type=NIHDataset.SPLIT_OFFICIAL_VAL_FROM_TEST,\n",
    "    classes=classes\n",
    ")\n",
    "transforms = A.Compose([\n",
    "    A.Resize(img_size, img_size),\n",
    "    tfm.NormalizeAlb(NIHDataset.MIN_MAX_VALUE,\n",
    "                     mean=[NIHDataset.MEAN] * 3,\n",
    "                     std=[NIHDataset.STD] * 3),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_set = NIHDataset(\n",
    "    dataset_path=dataset_path,\n",
    "    input_df=metadata['test_df'],\n",
    "    filter_by_positive_class=['Cardiomegaly']\n",
    "    # mode=NIHDataset.BBOX_ONLY_MODE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if hparams.architecture == 'eff_net_v2':\n",
    "    raise NotImplementedError()\n",
    "elif hparams.architecture == 'resnet':\n",
    "    # gradcam_target_layer = model.model.layer4[-3]\n",
    "    # gradcam_target_layer = model.model.layer3[-1]\n",
    "    gradcam_target_layer = model.model.layer4[0]\n",
    "else:\n",
    "    raise ValueError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from inference_utils.cam_predictor import CamPredictorMultiLabel\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from imageio.plugins.pillow import ndarray_to_pil\n",
    "import progressbar as pb\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "img_path = Path('images')\n",
    "img_path.mkdir(exist_ok=True)\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=2)\n",
    "\n",
    "cam_pred = CamPredictorMultiLabel(model, thresholds, gradcam_target_layer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, (img_raw, y_true) in pb.progressbar(enumerate(test_set)):\n",
    "    inference_result = {}\n",
    "    classification_report = {cls: {'detected': False} for cls in classes}\n",
    "    inference_result['classification_report'] = classification_report\n",
    "\n",
    "    img = transforms(image=img_raw)['image'].float()\n",
    "\n",
    "    img_raw_path = test_set.get_img_path(i)\n",
    "    img_root = img_path / img_raw_path.stem\n",
    "    img_root.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    scores, cam_list = cam_pred(img)\n",
    "    for class_idx, class_cam in cam_list:\n",
    "        cls_name = classes[class_idx]\n",
    "        img_debug_path = img_root / f'{cls_name}.png'\n",
    "        img_heatmap_path = img_root / f'{cls_name}_heatmap.png'\n",
    "        img_heatmap_rgb_path = img_root / (img_heatmap_path.stem + '_rgb.png')\n",
    "\n",
    "        report = classification_report[cls_name]\n",
    "        report['detected'] = True\n",
    "        # report['confidence'] = floor(float(y_pred[class_idx]) * 1000) / 1000\n",
    "        report['heatmap_url'] = img_heatmap_rgb_path.name\n",
    "\n",
    "        single_cam = cv2.resize(class_cam.detach().numpy(),\n",
    "                                img_raw.shape[:2],\n",
    "                                interpolation=cv2.INTER_NEAREST)\n",
    "        # img_norm = torch.tensor(img_raw).float().numpy() / 255\n",
    "\n",
    "        heatmap = cv2.applyColorMap(np.uint8(255 * single_cam), cv2.COLORMAP_JET)\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # visualization = np.float32(heatmap) + img_raw\n",
    "        # visualization = np.uint8(visualization / np.max(visualization) * 255)\n",
    "        #\n",
    "        # ndarray_to_pil(np.concatenate((visualization, np.uint8(img_raw)), axis=1)).save(img_debug_path)\n",
    "        # ndarray_to_pil(np.uint8(single_cam * 255)).save(img_heatmap_path)\n",
    "        executor.submit(ndarray_to_pil(heatmap).save, img_heatmap_rgb_path)\n",
    "        executor.submit(ndarray_to_pil(img_raw).save, img_root / img_raw_path.name)\n",
    "        # ndarray_to_pil(heatmap).save(img_heatmap_rgb_path)\n",
    "        # ndarray_to_pil(img_raw).save(img_root / img_raw_path.name)\n",
    "\n",
    "    with open(img_root / 'inference_result.json', 'w') as f:\n",
    "        json.dump(inference_result, f, indent=4, sort_keys=True)\n",
    "\n",
    "executor.shutdown(wait=True)\n",
    "# if i == 10:\n",
    "#     break\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}